{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a href=\"https://colab.research.google.com/github/ypeleg/keras_rl_tutorial/blob/master/1.0.1%20-%20QLearning%20Baby%20Steps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <center><strong><h5>Reinforcement Learning Tutorial!</h5></strong></center>\n",
    "    <center><strong><h2>1.0.1 - QLearning Baby Steps</h2></strong></center> \n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"img/animation1.gif?raw=true\" width=\"400\"></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div> \n",
    "    <center><strong><h2> Wait. What did just happen? </h2></strong></center> \n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning\n",
    "\n",
    "![Reinforcement Learning](https://raw.githubusercontent.com/ypeleg/keras_rl_tutorial/master/images/reinforcement.png \"Reinforcement Learning\")\n",
    "\n",
    "\n",
    "### Q-Learning Car\n",
    "\n",
    "\n",
    "Q-Learning works by building a table that provides a lookup table to determine which of several actions should be taken. As we move through a number of training episodes this table is refined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we would like to optimize the following:\n",
    "\n",
    "$y(s,a) = \\text{r} + \\gamma . \\underset{a'}{\\max} \\, Q_\\text{target}(s', a')$\n",
    "\n",
    "* $y(s,a)$ is the target Q-Value to train the online DQN for the state-action pair $(s, a)$.\n",
    "* $r$ is the reward actually collected after playing action $a$ in state $s$.\n",
    "* $\\gamma$ is the discount rate.\n",
    "* $s'$ is the state actually reached after played action $a$ in state $s$.\n",
    "* $a'$ is one of the possible actions in state $s'$.\n",
    "* $Q_\\text{target}(s', a')$ is the target DQN's estimate of the Q-Value of playing action $a'$ while in state $s'$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Q^{new}(s_{t},a_{t}) \\leftarrow (1-\\alpha) \\cdot \\underbrace{Q(s_{t},a_{t})}_{\\text{old value}} + \\underbrace{\\alpha}_{\\text{learning rate}} \\cdot  \\overbrace{\\bigg( \\underbrace{r_{t}}_{\\text{reward}} + \\underbrace{\\gamma}_{\\text{discount factor}} \\cdot \\underbrace{\\max_{a}Q(s_{t+1}, a)}_{\\text{estimate of optimal future value}} \\bigg) }^{\\text{learned value}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pygame\n",
    "import os \n",
    "os.chdir('/content')\n",
    "os.listdir('.')\n",
    "if not os.path.exists('keras_rl_tutorial'): os.system('git clone https://github.com/ypeleg/keras_rl_tutorial/')\n",
    "os.chdir('keras_rl_tutorial')\n",
    "os.environ['SDL_VIDEODRIVER']='dummy'\n",
    "import pygame.transform\n",
    "import pygame.display\n",
    "pygame.display.init()\n",
    "import sys \n",
    "import keras\n",
    "import pygame \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import pylab\n",
    "import sys\n",
    "sys.path.append(\"game/\")\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from game import wrapped_flappy_bird as game\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD , Adam\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "# These are for the Live Demo on stage\n",
    "vstack = np.vstack\n",
    "argmax = np.argmax\n",
    "append = lambda x, y: np.append(x, y, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'Train'\n",
    "GAMMA = 0.99\n",
    "BATCH = 32\n",
    "\n",
    "def build_model():\n",
    "    inp = Input(shape=(80, 80, 4))\n",
    "    X = Convolution2D(32, (8, 8), subsample=(4, 4), border_mode='same')(inp)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Convolution2D(64, (4, 4), subsample=(2, 2), border_mode='same')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Convolution2D(64, (3, 3), subsample=(1, 1), border_mode='same')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(512)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dense(2)(X)\n",
    "    model = Model(inputs=inp, outputs=X)\n",
    "    model.summary()\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=1e-4))\n",
    "    return model\n",
    "\n",
    "def init_flappybird():\n",
    "    env = game.GameState()\n",
    "    x_t, r_0, terminal = env.step(0)\n",
    "    x_t = x_t.reshape(x_t.shape[1], x_t.shape[2])\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])\n",
    "    return env, s_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple DQN For flappy bird "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "32/32 [==============================] - 0s 3ms/step - loss: 2626.2524\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed547d6b10>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Actual Algorithm Goes here:\n",
    "\n",
    "env, s_t = init_flappybird()\n",
    "model = build_model()\n",
    "D = deque()\n",
    "epsilon = 0.1\n",
    "\n",
    "for i in range(34):\n",
    "    if random.random() <= epsilon: a_t = random.randint(0, 1)\n",
    "    else: a_t = argmax(model.predict(s_t))\n",
    "    epsilon -= 3.33e-08\n",
    "    x_t1, r_t, done = env.step(a_t)\n",
    "    s_t1 = append(x_t1, s_t[:, :, :, :3])\n",
    "    D.append((s_t, a_t, r_t, s_t1, done))\n",
    "    if len(D) > BATCH:\n",
    "        X, y = [], []\n",
    "        for i in range(BATCH):\n",
    "            state_t, action_t, reward_t, state_t1, done = random.choice(D)\n",
    "            X.append(state_t)\n",
    "            y.append(model.predict(state_t)[0])\n",
    "            if not done: y[-1][action_t] = reward_t + GAMMA * np.max(model.predict(state_t1))\n",
    "            else: y[-1][action_t] = reward_t\n",
    "        model.fit(vstack(X), vstack(y), epochs=1)\n",
    "    s_t = s_t1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
